Warning: Log dir E:\Analogous-Disentangled-Actor-Critic\agents\data\ppo\ppo_s123 already exists! Storing info there anyway.
[32mLogging data to E:\Analogous-Disentangled-Actor-Critic\agents\data\ppo\ppo_s123\progress.txt
[36mSaving config:
{
    "ac_kwargs":	{
        "hidden_sizes":	[
            400,
            400
        ]
    },
    "actor_critic":	"MLPActorCritic",
    "clip_ratio":	0.2,
    "env_fn":	"<function <lambda> at 0x000002437E2B6D40>",
    "epochs":	50,
    "exp_name":	"ppo",
    "gamma":	0.99,
    "lam":	0.97,
    "logger":	{
        "<spinup.utils.logx.EpochLogger object at 0x000002437F2A0D60>":	{
            "epoch_dict":	{},
            "exp_name":	"ppo",
            "first_row":	true,
            "log_current_row":	{},
            "log_headers":	[],
            "output_dir":	"E:\\Analogous-Disentangled-Actor-Critic\\agents\\data\\ppo\\ppo_s123",
            "output_file":	{
                "<_io.TextIOWrapper name='E:\\\\Analogous-Disentangled-Actor-Critic\\\\agents\\\\data\\\\ppo\\\\ppo_s123\\\\progress.txt' mode='w' encoding='cp1252'>":	{
                    "mode":	"w"
                }
            }
        }
    },
    "logger_kwargs":	{
        "exp_name":	"ppo",
        "output_dir":	"E:\\Analogous-Disentangled-Actor-Critic\\agents\\data\\ppo\\ppo_s123"
    },
    "max_ep_len":	1000,
    "pi_lr":	0.0003,
    "save_freq":	10,
    "seed":	123,
    "steps_per_epoch":	4000,
    "target_kl":	0.01,
    "train_pi_iters":	80,
    "train_v_iters":	80,
    "vf_lr":	0.001
}
[32mNumber of parameters: 	 pi: 162802, 	 v: 162801
Warning: trajectory cut off by epoch at 5 steps.
[32mEarly stopping at step 1 due to reaching max kl.
D:\nlp\torchenv\lib\site-packages\gymnasium\envs\registration.py:517: DeprecationWarning: [33mWARN: The environment InvertedPendulum-v4 is out of date. You should consider upgrading to version `v5`.
  logger.deprecation(
---------------------------------------
|             Epoch |               0 |
|      AverageEpRet |             9.8 |
|          StdEpRet |            4.44 |
|          MaxEpRet |              27 |
|          MinEpRet |               3 |
|             EpLen |             9.8 |
|      AverageVVals |         -0.0816 |
|          StdVVals |          0.0219 |
|          MaxVVals |          0.0067 |
|          MinVVals |          -0.125 |
| TotalEnvInteracts |           4e+03 |
|            LossPi |        1.39e-07 |
|             LossV |            55.8 |
|       DeltaLossPi |        -0.00153 |
|        DeltaLossV |           -44.7 |
|           Entropy |           0.919 |
|                KL |          0.0686 |
|          ClipFrac |           0.385 |
|          StopIter |               1 |
|              Time |            5.51 |
---------------------------------------
Traceback (most recent call last):
  File "E:\Analogous-Disentangled-Actor-Critic\main.py", line 140, in <module>
    main()
  File "E:\Analogous-Disentangled-Actor-Critic\main.py", line 128, in main
    trainer = Trainer(args)
  File "E:\Analogous-Disentangled-Actor-Critic\trainers\Trainer.py", line 114, in __init__
    subprocess.run([sys.executable,"agents\\ppo.py",f"--env={args.env_name}",f"--run_id={args.wandb_id}"])
  File "D:\nlp\torchenv\lib\subprocess.py", line 505, in run
    stdout, stderr = process.communicate(input, timeout=timeout)
  File "D:\nlp\torchenv\lib\subprocess.py", line 1146, in communicate
    self.wait()
  File "D:\nlp\torchenv\lib\subprocess.py", line 1209, in wait
    return self._wait(timeout=timeout)
  File "D:\nlp\torchenv\lib\subprocess.py", line 1506, in _wait
    result = _winapi.WaitForSingleObject(self._handle,
KeyboardInterrupt