D:\nlp\torchenv\lib\site-packages\gymnasium\envs\registration.py:517: DeprecationWarning: [33mWARN: The environment InvertedPendulum-v4 is out of date. You should consider upgrading to version `v5`.
  logger.deprecation(
Warning: Log dir E:\Analogous-Disentangled-Actor-Critic\agents\data\InvertedPendulum-v4\InvertedPendulum-v4_s0 already exists! Storing info there anyway.
[32mLogging data to E:\Analogous-Disentangled-Actor-Critic\agents\data\InvertedPendulum-v4\InvertedPendulum-v4_s0\progress.txt
[36mSaving config:
{
    "exp_name":	"InvertedPendulum-v4",
    "logger":	{
        "<spinup.utils.logx.EpochLogger object at 0x000001BD1CDE2350>":	{
            "epoch_dict":	{},
            "exp_name":	"InvertedPendulum-v4",
            "first_row":	true,
            "log_current_row":	{},
            "log_headers":	[],
            "output_dir":	"E:\\Analogous-Disentangled-Actor-Critic\\agents\\data\\InvertedPendulum-v4\\InvertedPendulum-v4_s0",
            "output_file":	{
                "<_io.TextIOWrapper name='E:\\\\Analogous-Disentangled-Actor-Critic\\\\agents\\\\data\\\\InvertedPendulum-v4\\\\InvertedPendulum-v4_s0\\\\progress.txt' mode='w' encoding='cp1252'>":	{
                    "mode":	"w"
                }
            }
        }
    },
    "self":	{
        "<agents.sac.SAC object at 0x000001BD15260EB0>":	{
            "ac_kwargs":	{},
            "actor_critic":	"MLPActorCritic",
            "alpha":	0.2,
            "batch_size":	100,
            "device":	"cuda",
            "env_fn":	"<function SAC.__init__.<locals>.<lambda> at 0x000001BD1641CCA0>",
            "epochs":	100,
            "gamma":	0.99,
            "logger_kwargs":	{
                "exp_name":	"InvertedPendulum-v4",
                "output_dir":	"E:\\Analogous-Disentangled-Actor-Critic\\agents\\data\\InvertedPendulum-v4\\InvertedPendulum-v4_s0"
            },
            "lr":	0.001,
            "max_ep_len":	1000,
            "num_test_episodes":	10,
            "polyak":	0.995,
            "replay_size":	1000000,
            "save_freq":	1,
            "seed":	0,
            "start_steps":	10000,
            "steps_per_epoch":	4000,
            "update_after":	1000,
            "update_every":	50
        }
    }
}
[32mNumber of parameters: 	 pi: 67586, 	 q1: 67585, 	 q2: 67585
tensor([[ 0.2011],
        [-2.8251],
        [ 0.6828],
        [-2.7252],
        [ 2.6497],
        [ 0.5739],
        [ 2.3237],
        [-1.1640],
        [-0.6646],
        [ 1.0014],
        [ 1.9348],
        [ 1.8638],
        [-0.2444],
        [-0.9174],
        [ 1.4693],
        [ 0.4371],
        [ 1.9176],
        [-0.2419],
        [-0.1758],
        [-0.7224],
        [-2.9196],
        [ 1.0857],
        [ 0.6742],
        [ 0.2432],
        [ 1.9176],
        [ 2.9912],
        [ 1.8060],
        [-1.2439],
        [ 2.1970],
        [-1.8942],
        [-1.0840],
        [-2.1651],
        [ 1.2973],
        [-1.8304],
        [-1.1146],
        [ 2.4266],
        [ 0.1133],
        [-2.4406],
        [ 1.8303],
        [ 1.6642],
        [-0.5732],
        [ 0.7724],
        [-1.4443],
        [-1.1146],
        [ 1.7089],
        [ 1.3746],
        [ 0.6322],
        [ 1.2729],
        [-1.3123],
        [ 1.1807],
        [-2.6760],
        [ 2.4260],
        [-1.2981],
        [-2.3752],
        [ 1.5536],
        [-0.3334],
        [ 2.4983],
        [ 0.8420],
        [-1.3758],
        [-1.9941],
        [ 0.0493],
        [-0.3521],
        [-2.1461],
        [-1.3707],
        [ 2.5562],
        [-1.5779],
        [-0.2051],
        [-0.2051],
        [-2.5114],
        [ 2.1439],
        [ 2.0802],
        [-0.1140],
        [-1.4376],
        [-2.4961],
        [-2.3046],
        [-1.4897],
        [ 1.5191],
        [-2.4306],
        [ 2.6887],
        [ 2.9534],
        [-0.3334],
        [ 0.1859],
        [ 1.1656],
        [ 0.1684],
        [-2.2188],
        [-1.9033],
        [-1.2878],
        [ 0.7255],
        [-1.4115],
        [ 1.0003],
        [ 2.8601],
        [ 1.3516],
        [ 2.3144],
        [-0.3897],
        [ 0.1911],
        [ 2.7532],
        [ 1.4835],
        [ 1.7367],
        [-0.5323],
        [-2.4390]])
Traceback (most recent call last):
  File "E:\Analogous-Disentangled-Actor-Critic\main.py", line 141, in <module>
    main()
  File "E:\Analogous-Disentangled-Actor-Critic\main.py", line 129, in main
    trainer = Trainer(args)
  File "E:\Analogous-Disentangled-Actor-Critic\trainers\Trainer.py", line 117, in __init__
    sac.sac()
  File "E:\Analogous-Disentangled-Actor-Critic\agents\sac.py", line 350, in sac
    update(data=batch)
  File "E:\Analogous-Disentangled-Actor-Critic\agents\sac.py", line 261, in update
    loss_q, q_info = compute_loss_q(data)
  File "E:\Analogous-Disentangled-Actor-Critic\agents\sac.py", line 208, in compute_loss_q
    q1 = ac.q1(o,a)
  File "D:\nlp\torchenv\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Analogous-Disentangled-Actor-Critic\./agents\spinup\sac\core.py", line 77, in forward
    q = self.q(torch.cat([obs, act], dim=-1))
  File "D:\nlp\torchenv\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "D:\nlp\torchenv\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "D:\nlp\torchenv\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "D:\nlp\torchenv\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)